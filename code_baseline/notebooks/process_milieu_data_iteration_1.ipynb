{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:99% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "# make the Jupyter notebook use the full screen width\n",
    "display(HTML(\"<style>.container { width:99% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "ANNEX_regexp= r'^(ANNEX)\\ *([0-9.]|ONE|TWO|THREE|FOUR|FIVE|SIX|SEVEN|EIGHT|NINE|TEN|ELEVEN|TWELVE|THIRTEEN|FOURTEEN|FIFTEEN|SIXTEEN|SEVENTEEN|EIGHTEEN|NINETEEN|TWENTY|I|II|III|IV|V|VI|VII|VIII|IX|X|X(I|II|III|IV|V|VI|VII|VIII|IX|X))* *$'\n",
    "\n",
    "import sys\n",
    "from base64 import b64encode\n",
    "from base64 import b64decode\n",
    "\n",
    "\n",
    "sys.path.append(  \"/notebook/nas-trainings/arne/DGFISMA/definition_extraction/notebooks/\" )\n",
    "\n",
    "import requests\n",
    "from cleaning import clean_html\n",
    "\n",
    "\n",
    "#read in (train data)\n",
    "data=pd.read_csv(  \"/notebook/nas-trainings/arne/DGFISMA/DATA/doc_classifier/Milieu_GOLDEN_STANDARD/Milieu_iteratie_1.csv\"  , sep=',' , header=None ) \n",
    "\n",
    "https=data[0].tolist()\n",
    "labels=data[1].tolist()\n",
    "\n",
    "labels=[ 1 if label.strip()=='Accepted' else 0 for label in labels   ]\n",
    "\n",
    "assert( len( https ) == len( labels )  )\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "all_articles=[]\n",
    "\n",
    "for i,http in enumerate(https):\n",
    "\n",
    "    page_response=requests.get( http )\n",
    "\n",
    "    articles=clean_html( page_response.content.decode( 'utf-8' ) )\n",
    "\n",
    "    #delete the annexes:\n",
    "    articles_no_annexes=[]\n",
    "    for article in articles:\n",
    "        if bool(re.match( ANNEX_regexp,  article.strip(\"\\n\").split( \"\\n\" )[0]  , re.IGNORECASE )):\n",
    "            #continue\n",
    "            break  #not adding annexes, or anything that comes after annex to the training set\n",
    "        else:\n",
    "            articles_no_annexes.append( article )\n",
    "\n",
    "    if articles_no_annexes:\n",
    "        delimiter=100*\"â– \"\n",
    "        article_no_annexes=delimiter.join(  articles_no_annexes  )\n",
    "        all_articles.append( article_no_annexes )\n",
    "        \n",
    "    print(i)\n",
    "\n",
    "assert( len( all_articles  ) == len(labels) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed( 10 )\n",
    "\n",
    "labels_text=[]\n",
    "for label, text in zip( labels, all_articles  ):\n",
    "    labels_text.append(  ( label, text  ) )\n",
    "\n",
    "random.shuffle( labels_text )\n",
    "\n",
    "with open( os.path.join(  \"/notebook/nas-trainings/arne/DGFISMA/DATA/doc_classifier/processed_eurlex_15_06\", \"test_data_milieu_iteration1.tsv\"  ) , 'w'  ) as f:\n",
    "    for item in labels_text:\n",
    "        if item[0]==1:\n",
    "            label_name='accepted'\n",
    "        else:\n",
    "            label_name='declined'\n",
    "\n",
    "        encoded_doc=b64encode(  item[1].encode() )\n",
    "        f.write( f\"{encoded_doc.decode()  }\\t{ label_name }\\t{item[0]}\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88        24\n",
      "           1       0.89      0.62      0.73        13\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        37\n",
      "   macro avg       0.86      0.79      0.81        37\n",
      "weighted avg       0.85      0.84      0.83        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                         stop_words= 'english' )\n",
    "\n",
    "feature_selection=SelectFromModel(LinearSVC(penalty= \"l1\" , dual=False,\n",
    "                                                          tol=1e-3, class_weight='balanced'  )) \n",
    "\n",
    "classifier=LinearSVC(penalty=\"l1\", loss=\"squared_hinge\" , dual=False )\n",
    "#calibrated the classifier (for predict_proba): \n",
    "calibrated_classifier = CalibratedClassifierCV(classifier , cv=5 ) \n",
    "\n",
    "\n",
    "clf=Pipeline([\n",
    "( 'vectorizer', vectorizer)  ,\n",
    "#( 'chisquare', ch2  )  ,\n",
    "('feature_selection',  feature_selection  )   ,\n",
    "('classification', calibrated_classifier  )\n",
    "])\n",
    "\n",
    "\n",
    "random.seed( 10 )\n",
    "\n",
    "\n",
    "labels_text=[]\n",
    "for label, text in zip( labels, all_articles  ):\n",
    "    labels_text.append(  ( label, text  ) )\n",
    "    \n",
    "\n",
    "random.shuffle( labels_text )\n",
    "\n",
    "\n",
    "print( len(labels_text) )\n",
    "\n",
    "train_set=labels_text[:80]\n",
    "test_set=labels_text[ 80: ]\n",
    "\n",
    "train_labels=[ item[0] for item in train_set   ]\n",
    "train_data=[ item[1] for item in train_set   ]\n",
    "\n",
    "test_labels=[ item[0] for item in test_set   ]\n",
    "test_data=[ item[1] for item in test_set   ]\n",
    "\n",
    "clf.fit(  train_data , train_labels )\n",
    "\n",
    "pred=clf.predict( test_data  )\n",
    "\n",
    "print( metrics.classification_report( test_labels , pred ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
